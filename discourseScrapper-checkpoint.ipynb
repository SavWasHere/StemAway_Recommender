{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca4345f",
   "metadata": {},
   "source": [
    "# implement\n",
    "\n",
    "1. Non-Repeating Links [Done]\n",
    "\n",
    "2. Save Form Stats [Done]\n",
    "\n",
    "3. Proper scroll to the bottom [Done]\n",
    "\n",
    "4. Filter common phrases [Done]\n",
    "\n",
    "5. Regex (A-Z,(,),-) [Done]\n",
    "\n",
    "6. Differentiate between english and other languages [Working On]\n",
    "\n",
    "7. Look over Data (Are the words being retreived okay?)[Working On (Almost done)]\n",
    "\n",
    "8. Make code efficient (Any way you can make it so it runs a bit faster? Ex. Figuring out where timeouts are needed and where not)\n",
    "\n",
    "9. Make code cleaner (comments, proper PEP, convert to pyfile, FIX UR GODAMN VARIABLE NAMES)\n",
    "\n",
    "10. Remove any functions which you dont need into \"extraFunc.py\"\n",
    "\n",
    "11. Upload to github\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c2cb476",
   "metadata": {},
   "outputs": [],
   "source": [
    "class discourseWordScraper:\n",
    "    \n",
    "    def __init__ (self, basicLink, websitePage, specificClasses = [], specificTags = [], specificIds = [], specificCus = [], dicCusClass = []):\n",
    "        \n",
    "    \n",
    "        self.basicLink = basicLink\n",
    "        self.websitePage = websitePage\n",
    "        \n",
    "        self.specificClasses = specificClasses\n",
    "        self.specificTags = specificTags\n",
    "        self.specificIds = specificIds\n",
    "\n",
    "        self.bSoup = None\n",
    "\n",
    "        \n",
    "    def setVar(self, htmlData, websitePage):\n",
    "        self.bSoup = BeautifulSoup(htmlData.strip(), 'html.parser')\n",
    "        self.websitePage = websitePage\n",
    "        \n",
    "    def getByClass(self):\n",
    "        \n",
    "        tempData = list()\n",
    "        \n",
    "        for classTxt in self.specificClasses:\n",
    "            tempData += self.bSoup.find_all(class_=classTxt)\n",
    "            \n",
    "            \n",
    "        return ([x.text.split() for x in tempData], self.specificClasses)\n",
    "    \n",
    "    def getById(self):\n",
    "        \n",
    "        tempData = list()\n",
    "        \n",
    "        for idTxt in self.specificIds:\n",
    "            tempData += self.bSoup.find_all(id=idTxt)\n",
    "        return ([x.text.split('[,.\\s]') for x in tempData], self.specificId)\n",
    "        \n",
    "            \n",
    "    def getByTag(self):\n",
    "        \n",
    "        tempData = list()\n",
    "        \n",
    "        for tagTxt in self.specificTags:\n",
    "            tempData += self.bSoup.find_all(tagTxt)\n",
    "            \n",
    "        \n",
    "        return([x.text.split('[,.\\s]') for x in tempData], self.specificTags)\n",
    "        \n",
    "\n",
    "    \n",
    "    def getAllRelText(self):\n",
    "       \n",
    "        for script in self.bSoup([\"script\", \"style\"]):\n",
    "            script.extract()\n",
    "        \n",
    "        text = \"ALLTXT \"+ self.bSoup.get_text()\n",
    "        print(text)\n",
    "        return ([text.replace('\\n', \" \").split('[,.\\s]')], \"AllTxt\")\n",
    "        \n",
    "         \n",
    "        \n",
    "    def validateInput(self, tempData, typeCases, statsDict, repeating = True):\n",
    "        \n",
    "        blackList = [\"http\",\"img\",\"<p>\"] #<- NEEDS INPUT TO RUN\n",
    "        regex = re.compile(\"[^a-zA-Z-/_']\")\n",
    "        finalInput = list()\n",
    "        \n",
    "        \n",
    "        for rawSentence in tempData:\n",
    "                rawInput = ([regex.sub('', string.lower()) for string in rawSentence])\n",
    "                \n",
    "                finalInput.extend([string for string in rawInput if any(blackTag in string for blackTag in blackList) == False and string != \"\"])                \n",
    "\n",
    "        \n",
    "        print(finalInput)\n",
    "        \n",
    "        print(statsDict[\"date-scraped\"])\n",
    "        finalInput.insert(0, statsDict[\"date-scraped\"])\n",
    "        finalInput.insert(1, (self.basicLink + self.websitePage + \"/\"))\n",
    "        finalInput.insert(2, statsDict[\"created\"])\n",
    "        finalInput.insert(3, statsDict[\"last reply\"])\n",
    "        \n",
    "        try: finalInput.insert(4, statsDict[\"replies\"]) \n",
    "        except: finalInput.insert(4, statsDict[\"reply\"])\n",
    "        \n",
    "        try: finalInput.insert(5, statsDict[\"views\"])\n",
    "        except: finalInput.insert(5, statsDict[view])\n",
    "        \n",
    "        try: finalInput.insert(6, statsDict[\"users\"]) \n",
    "        except: finalInput.insert(6, statsDict[\"user\"])\n",
    "        \n",
    "        try:finalInput.insert(7, statsDict[\"likes\"])\n",
    "        except: finalInput.insert(7, statsDict[\"like\"])\n",
    "        \n",
    "        \n",
    "        try: finalInput.insert(8, statsDict[\"links\"])\n",
    "        except: finalInput.insert(8, statsDict[\"link\"])\n",
    "        \n",
    "        finalInput.insert(9, typeCases)\n",
    "    \n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "        return finalInput\n",
    "        \n",
    "            \n",
    "    def saveCSV(self, finalInput):\n",
    "        \n",
    "        with open('data.csv', 'r', encoding=\"utf-8\") as dfr, open('data.csv', 'a+', newline='', encoding=\"utf-8\") as dfw:\n",
    "            \n",
    "            \n",
    "            writer = csv.writer(dfw)\n",
    "            reader = csv.reader(dfr)\n",
    "           \n",
    "            writer.writerow(finalInput) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95439adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "class formNavigator():\n",
    "    \n",
    "    def __init__ (self, basicLink, websitePage=\"\", blackList = {}):\n",
    "        \n",
    "        self.basicLink = basicLink\n",
    "        self.websitePage = websitePage\n",
    "        self.currentLink = basicLink + websitePage\n",
    "        \n",
    "        self.linksStored = list()\n",
    "        self.blackList = {set}\n",
    "        \n",
    "        self.bSoup = None\n",
    "        \n",
    "        selService = Service('C:/Users/dilsh/Downloads/chromedriver_win32/chromedriver.exe')\n",
    "        \n",
    "        option = webdriver.ChromeOptions()\n",
    "        option.add_argument('--incognito')\n",
    "#         chrome_options.add_argument(\"--headless\")\n",
    "        \n",
    "        self.driver = webdriver.Chrome(service=selService, options=option)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def scrollPage(self, userRequest = \"down\",numOfTimes=\"infinite\"):\n",
    "        \n",
    "        last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        \n",
    "        if numOfTimes == \"infinite\":\n",
    "        \n",
    "            while True:\n",
    "\n",
    "                if userRequest == \"up\": new_height = self.driver.execute_script(\"window.scrollTo(0,0)\")\n",
    "                elif userRequest == \"down\": new_height = self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "                time.sleep(2)\n",
    "\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "\n",
    "                last_height = new_height\n",
    "            \n",
    "        else:\n",
    "                \n",
    "            for num in range(int(numOfTimes)):\n",
    "                \n",
    "                self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                print(\"hello\")\n",
    "                time.sleep(2)\n",
    "                \n",
    "\n",
    "\n",
    "                \n",
    "    \n",
    "    \n",
    "    def getPageHtml(self):\n",
    "        \n",
    "        self.driver.get(f'{self.currentLink}')\n",
    "        time.sleep(2)\n",
    "        \n",
    "        pageMeta = \"\"\n",
    "        \n",
    "        self.scrollPage(userRequest=\"up\")\n",
    "        \n",
    "        if \"/t/\" in self.currentLink:\n",
    "            pageMeta = self.getPageMeta(self.driver.page_source)\n",
    "            self.scrollPage(userRequest=\"down\")            \n",
    "            \n",
    "        elif \"/c/\" in self.currentLink: \n",
    "            self.scrollPage(numOfTimes = \"5\")\n",
    "            \n",
    "        else:\n",
    "            self.scrollPage(userRequest=\"down\")\n",
    "                \n",
    "        \n",
    "        with open(\"htmlStored.txt\", \"r+\", encoding='utf-8') as htmlPage:\n",
    "            htmlPage.write(self.driver.page_source) \n",
    "            \n",
    "        \n",
    "        self.bSoup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "        return self.bSoup, self.basicLink, self.websitePage, pageMeta\n",
    "    \n",
    "    def getPageMeta(self,html):\n",
    "        \n",
    "        print(self.currentLink)\n",
    "\n",
    "        now = datetime.now()\n",
    "        self.bSoup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        try:\n",
    "            infoUList = self.bSoup.find(\"div\", class_=\"topic-map\")\n",
    "            \n",
    "            dateList = [date.get(\"title\") for date in infoUList.find_all(\"span\", class_=\"relative-date\") if date.get(\"title\") != None][0:2]\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "            \n",
    "            liNumbers = [num.text for num in infoUList.find_all(\"span\", class_=\"number\") if num.text != None]\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "            desText = [decs.text for decs in infoUList.find_all(\"h4\") if decs.text != None]\n",
    "            metaDataDict = {desText[string]: (dateList + liNumbers)[string] for string in range(len(desText))}\n",
    "            \n",
    "            if \"likes\" not in metaDataDict and \"like\" not in metaDataDict: metaDataDict[\"likes\"] = \"0\"\n",
    "            if \"links\" not in metaDataDict and \"link\" not in metaDataDict: metaDataDict[\"links\"]= \"0\"\n",
    "            \n",
    "            \n",
    "            \n",
    "            metaDataDict[\"date-scraped\"] = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "            print(metaDataDict)\n",
    "                \n",
    "            return metaDataDict\n",
    "    \n",
    "        except AttributeError as e:\n",
    "            \n",
    "            metaDataDict = {'date-scraped': f'{now.strftime(\"%d/%m/%Y %H:%M:%S\")}','created': f'{self.bSoup.find(\"span\", class_=\"relative-date\").get(\"title\")}', 'last reply': '0', 'replies': '0', 'views': 'Unknown', 'users': '1', 'likes': 'Unknown', 'links':'Unknown'}\n",
    "            print(metaDataDict)\n",
    "            \n",
    "            return metaDataDict\n",
    "            \n",
    "    \n",
    "    def getLink(self):\n",
    "        \n",
    "        self.blackList.add(\"/c/international\")\n",
    "\n",
    "        \n",
    "        for aTag in self.bSoup.find_all(\"a\"):\n",
    "            \n",
    "            try:\n",
    "                aTag = (aTag.get(\"href\"))\n",
    "                \n",
    "                \n",
    "\n",
    "                if aTag.startswith(\"/t/\") or aTag.startswith(\"/c/\") :\n",
    "                    self.linksStored.append(aTag)\n",
    "   \n",
    "                \n",
    "            except AttributeError as a:\n",
    "                continue\n",
    "        \n",
    "        self.linksStored = list(dict.fromkeys(self.linksStored))\n",
    "                \n",
    "    \n",
    "    def setLink(self, userRequest):\n",
    "        \n",
    "        \n",
    "\n",
    "        self.websitePage = random.choice([item for item in self.linksStored if isinstance(item, str) and userRequest in item])\n",
    "        self.currentLink = self.basicLink + self.websitePage\n",
    "        self.driver.get(self.currentLink)   \n",
    "        \n",
    "        self.linksStored.remove(self.websitePage)\n",
    "        self.blackList.add(self.websitePage)\n",
    "        \n",
    "        return self.currentLink, userRequest\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f56d01a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "hello\n",
      "https://forums.unrealengine.com/t/resource-to-learn-best-practices-for-creating-high-performance-ai-mobs-npcs/614568\n",
      "{'created': 'Jul 26, 2022 4:35 am', 'last reply': 'Jul 26, 2022 5:12 am', 'reply': '1', 'views': '68', 'users': '2', 'likes': '4', 'links': '0', 'date-scraped': '27/07/2022 19:32:21'}\n",
      "['im', 'interested', 'in', 'the', 'ai', 'programming', 'side', 'of', 'things', 'for', 'a', 'traditional', 'rpg', 'does', 'anyone', 'know', 'of', 'resources', 'that', 'also', 'focus', 'on', 'performance', 'eg', 'whenever', 'i', 'hear', 'people', 'discuss', 'things', 'they', 'say', 'use', 'unavmovementcomponent', 'instead', 'of', 'ucharactermovementcomponent', 'dont', 'use', 'ticks', 'or', 'reduce', 'them', 'check', 'player', 'sight', 'etc', 'but', 'is', 'there', 'an', 'example/tutorial/resource', 'that', 'actually', 'implements', 'high', 'performance', 'ai', 'for', 'mobs/npcs', 'eg', 'for', 'a', 'traditional', 'mob', 'that', 'spawns', 'roams', 'has', 'some', 'idle', 'animations/walking', 'then', 'attacks', 'players', 'when', 'they', 'come', 'within', 'some', 'range', 'doesnt', 'even', 'have', 'to', 'be', 'range', 'of', 'sight', 'and', 'can', 'die/have', 'attributes', 'hi', 'there', 'if', 'you', 'examin', 'the', 'ai', 'shipped', 'with', 'lyra', 'started', 'game', 'you', 'want', 'to', 'check', 'both', 'behavior', 'trees', 'elimination', 'and', 'control', 'point', 'another', 'reference', 'is', 'shooter', 'game', 'shipped', 'with', 'behavior', 'tree', 'in', 'c', 'if', 'you', 'browse', 'the', 'community', 'tutorials', 'section', 'theres', 'a', 'tutorial', 'series', 'focusing', 'on', 'advanced', 'ai', 'with', 'leader', 'and', 'cover', 'system', 'also', 'in', 'c', 'im', 'watching', 'this', 'topic', 'because', 'i', 'am', 'looking', 'forward', 'to', 'seeing', 'recommendations', 'from', 'other', 'devs']\n",
      "27/07/2022 19:32:21\n",
      "https://forums.unrealengine.com/t/in-c-where-should-constant-strings-be-placed/608318\n",
      "{'created': 'Jul 19, 2022 2:27 am', 'last reply': 'Jul 26, 2022 11:40 am', 'replies': '2', 'views': '103', 'users': '2', 'link': '1', 'likes': '0', 'date-scraped': '27/07/2022 19:32:39'}\n",
      "['in', 'c', 'where', 'should', 'constant', 'strings', 'be', 'placed', 'in', 'java', 'you', 'can', 'write', 'an', 'interface', 'where', 'you', 'put', 'all', 'the', 'constant', 'strings', 'what', 'about', 'ue', 'c', 'for', 'what', 'purpose', 'you', 'can', 'define', 'static', 'const', 'strings', 'or', 'fnames', 'in', 'cpp', 'files', 'doesnt', 'have', 'to', 'be', 'part', 'of', 'a', 'class', 'or', 'interface', 'if', 'youre', 'thinking', 'about', 'localization', 'this', 'page', 'might', 'be', 'helpful', 'text', 'localization', 'unreal', 'engine', 'documentation', 'in', 'fact', 'it', 'is', 'for', 'unified', 'management', 'such', 'as', 'acpp', 'void', 'testtmapfstring', 'uobject', 'map', 'uobject', 'obj', 'mapname', 'bcpp', 'void', 'testtmapfstring', 'uobject', 'map', 'uobject', 'obj', 'mapname', 'the', 'same', 'map', 'is', 'used', 'in', 'different', 'files', 'i', 'want', 'key', 'to', 'be', 'a', 'constant', 'string', 'easy', 'to', 'maintain']\n",
      "27/07/2022 19:32:39\n"
     ]
    }
   ],
   "source": [
    "formNav = formNavigator(basicLink=\"https://forums.unrealengine.com\")\n",
    "\n",
    "startPageData = formNav.getPageHtml()\n",
    "wordScraper = discourseWordScraper(basicLink=startPageData[1], websitePage=startPageData[2], specificClasses=[\"cooked\"] )\n",
    "\n",
    "\n",
    "numIter = 0\n",
    "\n",
    "while numIter != 4:\n",
    "    \n",
    "    \n",
    "    if numIter >= 2: \n",
    "        \n",
    "        formNav.setLink(\"/t/\")\n",
    "        \n",
    "        formNav.scrollPage()\n",
    "        data = formNav.getPageHtml()\n",
    "        wordScraper.setVar(htmlData=str(data[0]), websitePage = data[2] )\n",
    "        html = wordScraper.getByClass()\n",
    "        wordScraper.saveCSV(finalInput=wordScraper.validateInput(tempData=html[0], typeCases=html[1], statsDict=data[3], repeating=True))\n",
    "        \n",
    "    \n",
    "    else: \n",
    "        formNav.getLink()\n",
    "        formNav.setLink(\"/c/\")\n",
    "        formNav.getPageHtml()\n",
    "        \n",
    "    numIter+=1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ecbeba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16398de3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
